{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image, ImageOps\n",
    "import chardet\n",
    "import re\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import os, sys \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only uncomment to load dataset locally to the vm\n",
    "\n",
    "#os.system('gsutil -m cp -r gs://marine-clarity-307511-aiplatform / .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def dataloader(filepath):\n",
    "\n",
    "    classes = [d for d in os.listdir(filepath) if os.path.isdir(os.path.join(filepath, d))]\n",
    "    image = [img for img in classes if img.find('frames_cleanpass') > -1]\n",
    "    disp  = [dsp for dsp in classes if dsp.find('disparity') > -1]\n",
    "\n",
    "    monkaa_path = filepath + [x for x in image if 'monkaa' in x][0]\n",
    "    monkaa_disp = filepath + [x for x in disp if 'monkaa' in x][0]\n",
    "\n",
    "\n",
    "    monkaa_dir  = os.listdir(monkaa_path)\n",
    "\n",
    "    all_left_img=[]\n",
    "    all_right_img=[]\n",
    "    all_left_disp = []\n",
    "    test_left_img=[]\n",
    "    test_right_img=[]\n",
    "    test_left_disp = []\n",
    "\n",
    "\n",
    "    for dd in monkaa_dir:\n",
    "        for im in os.listdir(monkaa_path+'/'+dd+'/left/'):\n",
    "            if is_image_file(monkaa_path+'/'+dd+'/left/'+im):\n",
    "                all_left_img.append(monkaa_path+'/'+dd+'/left/'+im)\n",
    "            all_left_disp.append(monkaa_disp+'/'+dd+'/left/'+im.split(\".\")[0]+'.pfm')\n",
    "\n",
    "        for im in os.listdir(monkaa_path+'/'+dd+'/right/'):\n",
    "            if is_image_file(monkaa_path+'/'+dd+'/right/'+im):\n",
    "                all_right_img.append(monkaa_path+'/'+dd+'/right/'+im)\n",
    "                \n",
    "    print(len(all_left_img), len(all_right_img), \"len monkaa\")\n",
    "\n",
    "    flying_path = filepath + [x for x in image if x == 'frames_cleanpass'][0]\n",
    "    flying_disp = filepath + [x for x in disp if x == 'frames_disparity'][0]\n",
    "    flying_dir = flying_path+'/TRAIN/'\n",
    "    subdir = ['A','B','C']\n",
    "\n",
    "    for ss in subdir:\n",
    "        flying = os.listdir(flying_dir+ss)\n",
    "\n",
    "        for ff in flying:\n",
    "\n",
    "                imm_l = os.listdir(flying_dir+ss+'/'+ff+'/left/')\n",
    "                for im in imm_l:\n",
    "                    if is_image_file(flying_dir+ss+'/'+ff+'/left/'+im):\n",
    "                        all_left_img.append(flying_dir+ss+'/'+ff+'/left/'+im)\n",
    "\n",
    "                    all_left_disp.append(flying_disp+'/TRAIN/'+ss+'/'+ff+'/left/'+im.split(\".\")[0]+'.pfm')\n",
    "\n",
    "                    if is_image_file(flying_dir+ss+'/'+ff+'/right/'+im):\n",
    "                        all_right_img.append(flying_dir+ss+'/'+ff+'/right/'+im)\n",
    "\n",
    "    flying_dir = flying_path+'/TEST/'\n",
    "\n",
    "    subdir = ['A','B','C']\n",
    "\n",
    "    for ss in subdir:\n",
    "        flying = os.listdir(flying_dir+ss)\n",
    "\n",
    "        for ff in flying:\n",
    "            imm_l = os.listdir(flying_dir+ss+'/'+ff+'/left/')\n",
    "            for im in imm_l:\n",
    "                if is_image_file(flying_dir+ss+'/'+ff+'/left/'+im):\n",
    "                    test_left_img.append(flying_dir+ss+'/'+ff+'/left/'+im)\n",
    "          \n",
    "                test_left_disp.append(flying_disp+'/TEST/'+ss+'/'+ff+'/left/'+im.split(\".\")[0]+'.pfm')\n",
    "\n",
    "                if is_image_file(flying_dir+ss+'/'+ff+'/right/'+im):\n",
    "                    test_right_img.append(flying_dir+ss+'/'+ff+'/right/'+im)\n",
    "\n",
    "    print(len(all_left_img), len(all_right_img), \"len 3d\")\n",
    "\n",
    "    driving_dir = filepath + [x for x in image if 'driving' in x][0] + '/'\n",
    "    driving_disp = filepath + [x for x in disp if 'driving' in x][0]\n",
    "\n",
    "    subdir1 = ['35mm_focallength','15mm_focallength']\n",
    "    subdir2 = ['scene_backwards','scene_forwards']\n",
    "    subdir3 = ['fast','slow']\n",
    "\n",
    "    for i in subdir1:\n",
    "        for j in subdir2:\n",
    "            for k in subdir3:\n",
    "                imm_l = os.listdir(driving_dir+i+'/'+j+'/'+k+'/left/')    \n",
    "                for im in imm_l:\n",
    "                    if is_image_file(driving_dir+i+'/'+j+'/'+k+'/left/'+im):\n",
    "                        all_left_img.append(driving_dir+i+'/'+j+'/'+k+'/left/'+im)\n",
    "\n",
    "                    all_left_disp.append(driving_disp+'/'+i+'/'+j+'/'+k+'/left/'+im.split(\".\")[0]+'.pfm')\n",
    "\n",
    "                    if is_image_file(driving_dir+i+'/'+j+'/'+k+'/right/'+im):\n",
    "                        all_right_img.append(driving_dir+i+'/'+j+'/'+k+'/right/'+im)\n",
    "    print(len(all_left_img), len(all_right_img), \"len driving\")\n",
    "\n",
    "    return all_left_img, all_right_img, all_left_disp, test_left_img, test_right_img, test_left_disp\n",
    "\n",
    "__imagenet_stats = {'mean': [0.485, 0.456, 0.406],\n",
    "                   'std': [0.229, 0.224, 0.225]}\n",
    "\n",
    "#__imagenet_stats = {'mean': [0.5, 0.5, 0.5],\n",
    "#                   'std': [0.5, 0.5, 0.5]}\n",
    "\n",
    "__imagenet_pca = {\n",
    "    'eigval': torch.Tensor([0.2175, 0.0188, 0.0045]),\n",
    "    'eigvec': torch.Tensor([\n",
    "        [-0.5675,  0.7192,  0.4009],\n",
    "        [-0.5808, -0.0045, -0.8140],\n",
    "        [-0.5836, -0.6948,  0.4203],\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "def scale_crop(input_size, scale_size=None, normalize=__imagenet_stats):\n",
    "    t_list = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**normalize),\n",
    "    ]\n",
    "    #if scale_size != input_size:\n",
    "    #t_list = [transforms.Scale((960,540))] + t_list\n",
    "\n",
    "    return transforms.Compose(t_list)\n",
    "\n",
    "\n",
    "def scale_random_crop(input_size, scale_size=None, normalize=__imagenet_stats):\n",
    "    t_list = [\n",
    "        transforms.RandomCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**normalize),\n",
    "    ]\n",
    "    if scale_size != input_size:\n",
    "        t_list = [transforms.Scale(scale_size)] + t_list\n",
    "\n",
    "    transforms.Compose(t_list)\n",
    "\n",
    "\n",
    "def pad_random_crop(input_size, scale_size=None, normalize=__imagenet_stats):\n",
    "    padding = int((scale_size - input_size) / 2)\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomCrop(input_size, padding=padding),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**normalize),\n",
    "    ])\n",
    "\n",
    "\n",
    "def inception_preproccess(input_size, normalize=__imagenet_stats):\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomSizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**normalize)\n",
    "    ])\n",
    "def inception_color_preproccess(input_size, normalize=__imagenet_stats):\n",
    "    return transforms.Compose([\n",
    "        #transforms.RandomSizedCrop(input_size),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        ColorJitter(\n",
    "            brightness=0.4,\n",
    "            contrast=0.4,\n",
    "            saturation=0.4,\n",
    "        ),\n",
    "        Lighting(0.1, __imagenet_pca['eigval'], __imagenet_pca['eigvec']),\n",
    "        transforms.Normalize(**normalize)\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_transform(name='imagenet', input_size=None,\n",
    "                  scale_size=None, normalize=None, augment=True):\n",
    "    normalize = __imagenet_stats\n",
    "    input_size = 256\n",
    "    if augment:\n",
    "            return inception_color_preproccess(input_size, normalize=normalize)\n",
    "    else:\n",
    "            return scale_crop(input_size=input_size,\n",
    "                              scale_size=scale_size, normalize=normalize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Lighting(object):\n",
    "    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n",
    "\n",
    "    def __init__(self, alphastd, eigval, eigvec):\n",
    "        self.alphastd = alphastd\n",
    "        self.eigval = eigval\n",
    "        self.eigvec = eigvec\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.alphastd == 0:\n",
    "            return img\n",
    "\n",
    "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
    "        rgb = self.eigvec.type_as(img).clone()\\\n",
    "            .mul(alpha.view(1, 3).expand(3, 3))\\\n",
    "            .mul(self.eigval.view(1, 3).expand(3, 3))\\\n",
    "            .sum(1).squeeze()\n",
    "\n",
    "        return img.add(rgb.view(3, 1, 1).expand_as(img))\n",
    "\n",
    "\n",
    "class Grayscale(object):\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = img.clone()\n",
    "        gs[0].mul_(0.299).add_(0.587, gs[1]).add_(0.114, gs[2])\n",
    "        gs[1].copy_(gs[0])\n",
    "        gs[2].copy_(gs[0])\n",
    "        return gs\n",
    "\n",
    "\n",
    "class Saturation(object):\n",
    "\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = Grayscale()(img)\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class Brightness(object):\n",
    "\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = img.new().resize_as_(img).zero_()\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class Contrast(object):\n",
    "\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = Grayscale()(img)\n",
    "        gs.fill_(gs.mean())\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class RandomOrder(object):\n",
    "    \"\"\" Composes several transforms together in random order.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.transforms is None:\n",
    "            return img\n",
    "        order = torch.randperm(len(self.transforms))\n",
    "        for i in order:\n",
    "            img = self.transforms[i](img)\n",
    "        return img\n",
    "\n",
    "\n",
    "class ColorJitter(RandomOrder):\n",
    "\n",
    "    def __init__(self, brightness=0.4, contrast=0.4, saturation=0.4):\n",
    "        self.transforms = []\n",
    "        if brightness != 0:\n",
    "            self.transforms.append(Brightness(brightness))\n",
    "        if contrast != 0:\n",
    "            self.transforms.append(Contrast(contrast))\n",
    "        if saturation != 0:\n",
    "            self.transforms.append(Saturation(saturation))\n",
    "\n",
    "def readPFM(file):\n",
    "    file = open(file, 'rb')\n",
    "\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().rstrip()\n",
    "    encode_type = chardet.detect(header)  \n",
    "    header = header.decode(encode_type['encoding'])\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode(encode_type['encoding']))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().rstrip().decode(encode_type['encoding']))\n",
    "    if scale < 0: # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>' # big-endian\n",
    "    \n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    try:\n",
    "        data = np.reshape(data, shape)\n",
    "    except:\n",
    "        print(file)\n",
    "        print(\"not the right shape, use only zeros\")\n",
    "        data = np.zeros((540, 960))\n",
    "    \n",
    "    data = np.flipud(data)\n",
    "    return data, scale\n",
    "\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "def disparity_loader(path):\n",
    "    return readPFM(path)\n",
    "\n",
    "class myImageFloder(data.Dataset):\n",
    "    def __init__(self, left, right, left_disparity, training, loader=default_loader, dploader= disparity_loader):\n",
    " \n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.disp_L = left_disparity\n",
    "        self.loader = loader\n",
    "        self.dploader = dploader\n",
    "        self.training = training\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        left  = self.left[index]\n",
    "        right = self.right[index]\n",
    "        disp_L= self.disp_L[index]\n",
    "\n",
    "\n",
    "        left_img = self.loader(left)\n",
    "        right_img = self.loader(right)\n",
    "        dataL, scaleL = self.dploader(disp_L)\n",
    "        dataL = np.ascontiguousarray(dataL,dtype=np.float32)\n",
    "\n",
    "        if self.training:  \n",
    "            w, h = left_img.size\n",
    "            th, tw = 256, 512\n",
    "\n",
    "            x1 = random.randint(0, w - tw)\n",
    "            y1 = random.randint(0, h - th)\n",
    "\n",
    "            left_img = left_img.crop((x1, y1, x1 + tw, y1 + th))\n",
    "            right_img = right_img.crop((x1, y1, x1 + tw, y1 + th))\n",
    "\n",
    "            dataL = dataL[y1:y1 + th, x1:x1 + tw]\n",
    "\n",
    "            processed = get_transform(augment=False)  \n",
    "            left_img   = processed(left_img)\n",
    "            right_img  = processed(right_img)\n",
    "\n",
    "            return left_img, right_img, dataL\n",
    "        else:\n",
    "            processed = get_transform(augment=False)  \n",
    "            left_img       = processed(left_img)\n",
    "            right_img      = processed(right_img) \n",
    "            return left_img, right_img, dataL\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.left)\n",
    "\n",
    "    \n",
    "def convbn(in_planes, out_planes, kernel_size, stride, pad, dilation):\n",
    "\n",
    "    return nn.Sequential(nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=dilation if dilation > 1 else pad, dilation = dilation, bias=False),\n",
    "                         nn.BatchNorm2d(out_planes))\n",
    "\n",
    "\n",
    "def convbn_3d(in_planes, out_planes, kernel_size, stride, pad):\n",
    "\n",
    "    return nn.Sequential(nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, padding=pad, stride=stride,bias=False),\n",
    "                         nn.BatchNorm3d(out_planes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride, downsample, pad, dilation):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(convbn(inplanes, planes, 3, stride, pad, dilation),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv2 = convbn(planes, planes, 3, 1, pad, dilation)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        out += x\n",
    "\n",
    "        return out\n",
    "\n",
    "class disparityregression(nn.Module):\n",
    "    def __init__(self, maxdisp):\n",
    "        super(disparityregression, self).__init__()\n",
    "        self.disp = torch.Tensor(np.reshape(np.array(range(maxdisp)),[1, maxdisp,1,1])).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.sum(x*self.disp.data,1, keepdim=True)\n",
    "        return out\n",
    "\n",
    "class feature_extraction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(feature_extraction, self).__init__()\n",
    "        self.inplanes = 32\n",
    "        self.firstconv = nn.Sequential(convbn(3, 32, 3, 2, 1, 1),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       convbn(32, 32, 3, 1, 1, 1),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       convbn(32, 32, 3, 1, 1, 1),\n",
    "                                       nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock, 32, 3, 1,1,1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 64, 16, 2,1,1) \n",
    "        self.layer3 = self._make_layer(BasicBlock, 128, 3, 1,1,1)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 128, 3, 1,1,2)\n",
    "\n",
    "        self.branch1 = nn.Sequential(nn.AvgPool2d((64, 64), stride=(64,64)),\n",
    "                                     convbn(128, 32, 1, 1, 0, 1),\n",
    "                                     nn.ReLU(inplace=True))\n",
    "\n",
    "        self.branch2 = nn.Sequential(nn.AvgPool2d((32, 32), stride=(32,32)),\n",
    "                                     convbn(128, 32, 1, 1, 0, 1),\n",
    "                                     nn.ReLU(inplace=True))\n",
    "\n",
    "        self.branch3 = nn.Sequential(nn.AvgPool2d((16, 16), stride=(16,16)),\n",
    "                                     convbn(128, 32, 1, 1, 0, 1),\n",
    "                                     nn.ReLU(inplace=True))\n",
    "\n",
    "        self.branch4 = nn.Sequential(nn.AvgPool2d((8, 8), stride=(8,8)),\n",
    "                                     convbn(128, 32, 1, 1, 0, 1),\n",
    "                                     nn.ReLU(inplace=True))\n",
    "\n",
    "        self.lastconv = nn.Sequential(convbn(320, 128, 3, 1, 1, 1),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Conv2d(128, 32, kernel_size=1, padding=0, stride = 1, bias=False))\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride, pad, dilation):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "           downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),)\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, pad, dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,1,None,pad,dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output      = self.firstconv(x)\n",
    "        output      = self.layer1(output)\n",
    "        output_raw  = self.layer2(output)\n",
    "        output      = self.layer3(output_raw)\n",
    "        output_skip = self.layer4(output)\n",
    "\n",
    "\n",
    "        output_branch1 = self.branch1(output_skip)\n",
    "        output_branch1 = F.interpolate(output_branch1, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear', align_corners=True)\n",
    "\n",
    "        output_branch2 = self.branch2(output_skip)\n",
    "        output_branch2 = F.interpolate(output_branch2, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear', align_corners=True)\n",
    "\n",
    "        output_branch3 = self.branch3(output_skip)\n",
    "        output_branch3 = F.interpolate(output_branch3, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear', align_corners=True)\n",
    "\n",
    "        output_branch4 = self.branch4(output_skip)\n",
    "        output_branch4 = F.interpolate(output_branch4, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear', align_corners=True)\n",
    "\n",
    "        output_feature = torch.cat((output_raw, output_skip, output_branch4, output_branch3, output_branch2, output_branch1), 1)\n",
    "        output_feature = self.lastconv(output_feature)\n",
    "\n",
    "        return output_feature\n",
    "\n",
    "class PSMNet_basic(nn.Module):\n",
    "    def __init__(self, maxdisp):\n",
    "        super(PSMNet_basic, self).__init__()\n",
    "        self.maxdisp = maxdisp\n",
    "        self.feature_extraction = feature_extraction()\n",
    "\n",
    "########\n",
    "        self.dres0 = nn.Sequential(convbn_3d(64, 32, 3, 1, 1),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     convbn_3d(32, 32, 3, 1, 1),\n",
    "                                     nn.ReLU(inplace=True))\n",
    "\n",
    "        self.dres1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
    "\n",
    "        self.dres2 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   convbn_3d(32, 32, 3, 1, 1))\n",
    " \n",
    "        self.dres3 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
    "\n",
    "        self.dres4 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
    " \n",
    "        self.classify = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.Conv3d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1]*m.kernel_size[2] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, left, right):\n",
    "\n",
    "        refimg_fea     = self.feature_extraction(left)\n",
    "        targetimg_fea  = self.feature_extraction(right)\n",
    " \n",
    "        #matching\n",
    "        cost = Variable(torch.FloatTensor(refimg_fea.size()[0], refimg_fea.size()[1]*2, self.maxdisp/4,  refimg_fea.size()[2],  refimg_fea.size()[3]).zero_(), volatile= not self.training).cuda()\n",
    "\n",
    "        for i in range(self.maxdisp/4):\n",
    "            if i > 0 :\n",
    "             cost[:, :refimg_fea.size()[1], i, :,i:]   = refimg_fea[:,:,:,i:]\n",
    "             cost[:, refimg_fea.size()[1]:, i, :,i:] = targetimg_fea[:,:,:,:-i]\n",
    "            else:\n",
    "             cost[:, :refimg_fea.size()[1], i, :,:]   = refimg_fea\n",
    "             cost[:, refimg_fea.size()[1]:, i, :,:]   = targetimg_fea\n",
    "        cost = cost.contiguous()\n",
    "\n",
    "        cost0 = self.dres0(cost)\n",
    "        cost0 = self.dres1(cost0) + cost0\n",
    "        cost0 = self.dres2(cost0) + cost0 \n",
    "        cost0 = self.dres3(cost0) + cost0 \n",
    "        cost0 = self.dres4(cost0) + cost0\n",
    "\n",
    "        cost = self.classify(cost0)\n",
    "        cost = F.upsample(cost, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear')\n",
    "        cost = torch.squeeze(cost,1)\n",
    "        pred = F.softmax(cost)\n",
    "        pred = disparityregression(self.maxdisp)(pred)\n",
    "\n",
    "        return pred\n",
    "class hourglass(nn.Module):\n",
    "    def __init__(self, inplanes):\n",
    "        super(hourglass, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(convbn_3d(inplanes, inplanes*2, kernel_size=3, stride=2, pad=1),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv2 = convbn_3d(inplanes*2, inplanes*2, kernel_size=3, stride=1, pad=1)\n",
    "\n",
    "        self.conv3 = nn.Sequential(convbn_3d(inplanes*2, inplanes*2, kernel_size=3, stride=2, pad=1),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv4 = nn.Sequential(convbn_3d(inplanes*2, inplanes*2, kernel_size=3, stride=1, pad=1),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv5 = nn.Sequential(nn.ConvTranspose3d(inplanes*2, inplanes*2, kernel_size=3, padding=1, output_padding=1, stride=2,bias=False),\n",
    "                                   nn.BatchNorm3d(inplanes*2)) #+conv2\n",
    "\n",
    "        self.conv6 = nn.Sequential(nn.ConvTranspose3d(inplanes*2, inplanes, kernel_size=3, padding=1, output_padding=1, stride=2,bias=False),\n",
    "                                   nn.BatchNorm3d(inplanes)) #+x\n",
    "\n",
    "    def forward(self, x ,presqu, postsqu):\n",
    "        \n",
    "        out  = self.conv1(x) #in:1/4 out:1/8\n",
    "        pre  = self.conv2(out) #in:1/8 out:1/8\n",
    "        if postsqu is not None:\n",
    "           pre = F.relu(pre + postsqu, inplace=True)\n",
    "        else:\n",
    "           pre = F.relu(pre, inplace=True)\n",
    "\n",
    "        out  = self.conv3(pre) #in:1/8 out:1/16\n",
    "        out  = self.conv4(out) #in:1/16 out:1/16\n",
    "\n",
    "        if presqu is not None:\n",
    "           post = F.relu(self.conv5(out)+presqu, inplace=True) #in:1/16 out:1/8\n",
    "        else:\n",
    "           post = F.relu(self.conv5(out)+pre, inplace=True) \n",
    "\n",
    "        out  = self.conv6(post)  #in:1/8 out:1/4\n",
    "\n",
    "        return out, pre, post\n",
    "\n",
    "class PSMNet_stackhourglass(nn.Module):\n",
    "    def __init__(self, maxdisp):\n",
    "        super(PSMNet_stackhourglass, self).__init__()\n",
    "        self.maxdisp = maxdisp\n",
    "\n",
    "        self.feature_extraction = feature_extraction()\n",
    "\n",
    "        self.dres0 = nn.Sequential(convbn_3d(64, 32, 3, 1, 1),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     convbn_3d(32, 32, 3, 1, 1),\n",
    "                                     nn.ReLU(inplace=True))\n",
    "\n",
    "        self.dres1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
    "\n",
    "        self.dres2 = hourglass(32)\n",
    "\n",
    "        self.dres3 = hourglass(32)\n",
    "\n",
    "        self.dres4 = hourglass(32)\n",
    "\n",
    "        self.classif1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
    "\n",
    "        self.classif2 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
    "\n",
    "        self.classif3 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.Conv3d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1]*m.kernel_size[2] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, left, right):\n",
    "\n",
    "        refimg_fea     = self.feature_extraction(left)\n",
    "        targetimg_fea  = self.feature_extraction(right)\n",
    "\n",
    "\n",
    "        #matching\n",
    "        cost = Variable(torch.FloatTensor(refimg_fea.size()[0], refimg_fea.size()[1]*2, self.maxdisp//4,  refimg_fea.size()[2],  refimg_fea.size()[3]).zero_()).cuda()\n",
    "\n",
    "        for i in range(self.maxdisp//4):\n",
    "            if i > 0 :\n",
    "             cost[:, :refimg_fea.size()[1], i, :,i:]   = refimg_fea[:,:,:,i:]\n",
    "             cost[:, refimg_fea.size()[1]:, i, :,i:] = targetimg_fea[:,:,:,:-i]\n",
    "            else:\n",
    "             cost[:, :refimg_fea.size()[1], i, :,:]   = refimg_fea\n",
    "             cost[:, refimg_fea.size()[1]:, i, :,:]   = targetimg_fea\n",
    "        cost = cost.contiguous()\n",
    "\n",
    "        cost0 = self.dres0(cost)\n",
    "        cost0 = self.dres1(cost0) + cost0\n",
    "\n",
    "        out1, pre1, post1 = self.dres2(cost0, None, None) \n",
    "        out1 = out1+cost0\n",
    "\n",
    "        out2, pre2, post2 = self.dres3(out1, pre1, post1) \n",
    "        out2 = out2+cost0\n",
    "\n",
    "        out3, pre3, post3 = self.dres4(out2, pre1, post2) \n",
    "        out3 = out3+cost0\n",
    "\n",
    "        cost1 = self.classif1(out1)\n",
    "        cost2 = self.classif2(out2) + cost1\n",
    "        cost3 = self.classif3(out3) + cost2\n",
    "\n",
    "        if self.training:\n",
    "            cost1 = F.interpolate(cost1, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear', align_corners=True)\n",
    "            cost2 = F.interpolate(cost2, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear', align_corners=True)\n",
    "\n",
    "            cost1 = torch.squeeze(cost1,1)\n",
    "            pred1 = F.softmax(cost1,dim=1)\n",
    "            pred1 = disparityregression(self.maxdisp)(pred1)\n",
    "\n",
    "            cost2 = torch.squeeze(cost2,1)\n",
    "            pred2 = F.softmax(cost2,dim=1)\n",
    "            pred2 = disparityregression(self.maxdisp)(pred2)\n",
    "\n",
    "        cost3 = F.interpolate(cost3, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear', align_corners=True)\n",
    "        cost3 = torch.squeeze(cost3,1)\n",
    "        pred3 = F.softmax(cost3,dim=1)\n",
    "        #For your information: This formulation 'softmax(c)' learned \"similarity\" \n",
    "        #while 'softmax(-c)' learned 'matching cost' as mentioned in the paper.\n",
    "        #However, 'c' or '-c' do not affect the performance because feature-based cost volume provided flexibility.\n",
    "        pred3 = disparityregression(self.maxdisp)(pred3)\n",
    "\n",
    "        if self.training:\n",
    "            return pred1, pred2, pred3\n",
    "        else:\n",
    "            return pred3\n",
    "\n",
    "        "

